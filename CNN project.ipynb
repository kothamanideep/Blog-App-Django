{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUeME40iX8/nvX8RUMcj7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kothamanideep/Blog-App-Django/blob/master/CNN%20project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Team Membes:\n",
        "1.Manoj Kalal (101153172)\n",
        "2.Sivagopireddy yerredula (101143319)"
      ],
      "metadata": {
        "id": "N4kX2MDDnzNa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UldLzIRvjLvX"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import Activation\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSVYMn_EjQo1",
        "outputId": "d9f5e6d7-274f-476f-b016-e6c970eb9d86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "uyGyfLEojuHE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
        "    Activation('relu'),\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "mlvFZVaTjyuY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AEGRNccTj3a0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmIedeTunGbj",
        "outputId": "dd984c1f-c9a7-4a21-8863-ef1e02ba73c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 403s 214ms/step - loss: 0.0976 - accuracy: 0.9695 - val_loss: 0.0343 - val_accuracy: 0.9892\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 344s 184ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.0257 - val_accuracy: 0.9916\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 359s 192ms/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.0254 - val_accuracy: 0.9923\n",
            "Epoch 4/10\n",
            " 299/1875 [===>..........................] - ETA: 4:50 - loss: 0.0117 - accuracy: 0.9964"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "YzNil-xpnKe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I__B58HFnUoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=10, validation_data=(X_val_fold, y_val_fold))\n",
        "    val_loss, val_acc = model.evaluate(X_val_fold, y_val_fold)\n",
        "    scores.append(val_acc)\n",
        "\n",
        "print(f'K-Fold cross-validation accuracy: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})')\n"
      ],
      "metadata": {
        "id": "WXiKnzS5nZ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "confusion_mtx = confusion_matrix(y_test.argmax(axis=1), y_pred_classes)\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_mtx)"
      ],
      "metadata": {
        "id": "dN_PMiGqne7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sqBZJcFntSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation and Analysis\n",
        "\n",
        "# 1. CNN Architecture:\n",
        "#    The model consists of 3 convolutional layers with ReLU activation.\n",
        "#    Max pooling layers follow the 2nd and 3rd convolutional layers.\n",
        "#    The feature maps are flattened and fed into a fully connected layer with 256 neurons and ReLU activation.\n",
        "#    The output layer has 10 neurons with softmax activation for multi-class classification.\n",
        "\n",
        "# 2. Max Pooling:\n",
        "#    Max pooling is applied to downsample the feature maps while retaining the most prominent features.\n",
        "#    This reduces the computational complexity and helps capture the most relevant information.\n",
        "\n",
        "# 3. Fully Connected Layer and Softmax:\n",
        "#    The flattened feature maps are fed into a fully connected layer with 256 neurons and ReLU activation.\n",
        "#    The output layer applies softmax activation to produce class probabilities for each input digit.\n",
        "\n",
        "# 4. Training and Evaluation:\n",
        "#    The model is trained on the MNIST dataset using categorical cross-entropy loss and the Adam optimizer.\n",
        "#    The training and validation accuracy are plotted for visualization.\n",
        "#    K-Fold cross-validation is performed to evaluate the model's performance and generalization.\n",
        "#    The confusion matrix is computed to analyze the model's misclassifications.\n",
        "\n",
        "#  5. Training and Evaluation Analysis:\n",
        "#    - The model is trained for 10 epochs on the MNIST dataset, which is a reasonable number of epochs for this task.\n",
        "#    - During training, the model's performance is monitored using the categorical cross-entropy loss function.\n",
        "#    - The Adam optimizer is used for updating the model's weights during training, which is a popular and effective optimization algorithm.\n",
        "#    - The validation data (X_test, y_test) is used to evaluate the model's performance after each epoch during training.\n",
        "#    - The training and validation accuracy are plotted to visualize the model's learning curve.\n",
        "#    - K-Fold cross-validation with 5 folds is performed to assess the model's generalization performance.\n",
        "#    - The mean and standard deviation of the K-Fold cross-validation accuracy are reported.\n",
        "#    - The confusion matrix is computed to analyze the model's misclassifications on the test data.\n",
        "#    - The confusion matrix provides insights into which classes the model struggles with and which classes are easily distinguishable.\n",
        "#    - Based on the analysis of the training process, evaluation metrics, and confusion matrix, the model's performance can be interpreted, and potential areas for improvement can be identified."
      ],
      "metadata": {
        "id": "KOHQH1mdnu9m"
      }
    }
  ]
}